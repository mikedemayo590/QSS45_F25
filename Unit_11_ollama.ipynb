{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ac55ce-4c17-40f5-bf59-5bb20e942030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, random\n",
    "import json\n",
    "OLLAMA=\"http://127.0.0.1:11434\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65459b90-a100-4af9-9e6b-a5e890d18758",
   "metadata": {},
   "source": [
    "### What is requests?\n",
    "Demo using URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6cd5d1-d333-411d-8f15-529c58d87dff",
   "metadata": {},
   "source": [
    "### Requesting an output from Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4d8e56-c047-47fa-8904-a18f87db0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_chat(prompt, model=\"llama3\"):\n",
    "    \"\"\"Send a single prompt to a local Ollama model and return the response.\"\"\"\n",
    "    r = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": model, \"prompt\": prompt},\n",
    "        stream=True\n",
    "    )\n",
    "    output = \"\"\n",
    "    for line in r.iter_lines():\n",
    "        if line:\n",
    "            data = json.loads(line)\n",
    "            token = data.get(\"response\", \"\")\n",
    "            print(token, end=\"\", flush=True)\n",
    "            output += token\n",
    "    print()  # newline at end\n",
    "    # return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0af84d-4fe8-4b93-966c-3c5bf243746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eternal question!\n",
      "\n",
      "It's impossible for me to predict with certainty who will win the 2025 World Series, as it depends on many factors such as team performance, player injuries, trades, and other unexpected events that can occur during the season.\n",
      "\n",
      "However, I can give you some insights based on the current MLB landscape. The teams that have been consistently strong in recent years include:\n",
      "\n",
      "1. Houston Astros: With their deep farm system and strong pitching, they're always a contender.\n",
      "2. New York Yankees: Despite some ups and downs, they've remained one of the most consistent powerhouses in baseball.\n",
      "3. Los Angeles Dodgers: They've become a staple in the postseason, with a talented young core and a strong organization.\n",
      "\n",
      "Other teams that have shown promise or have made significant offseason moves include:\n",
      "\n",
      "1. Toronto Blue Jays: With their impressive young rotation and revamped offense, they're looking to make a deep run.\n",
      "2. Boston Red Sox: After a few years of rebuilding, they've assembled a solid roster with plenty of potential.\n",
      "3. Atlanta Braves: They've built a strong core through their farm system and have made savvy trades.\n",
      "\n",
      "Keep in mind that the MLB season is full of surprises, and teams can rise or fall quickly based on various factors. The 2025 World Series winner will likely be a team that peels out from the pack during the regular season and makes the most of their opportunities come October.\n",
      "\n",
      "Would you like me to make some hypothetical predictions or discuss any specific teams you're interested in?\n"
     ]
    }
   ],
   "source": [
    "ollama_chat(\"Who will win the 2025 World Series?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c90368-449c-4b5d-bd18-537137fc6ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aea01d77-8b93-4d24-953c-50f7c14abecc",
   "metadata": {},
   "source": [
    "## Quick task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7719f331-26f1-4018-a837-7a31f0183a77",
   "metadata": {},
   "source": [
    "- Write a short script that has Llama chat with itself for 5 rounds. \n",
    "- Ask it to keep it's answers brief, and input the previous rounds conversation into the next output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf224cd3-8eae-4350-910e-f5f608e83f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432335d1-6f2f-42c9-9ed1-ac6b6f63fcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693d77e-a47a-4745-b719-c47babb30c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa0f01-1678-4727-9e63-23a89c6e67d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85029e43-fb15-4b0c-970e-2460842f8edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0862dff-5880-4310-b213-1de78255a820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
