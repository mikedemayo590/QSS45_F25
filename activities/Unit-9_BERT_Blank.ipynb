{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c401be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcfcea3-2929-4953-b09a-f5a7cc36cf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/datasets/_twenty_newsgroups.py:79: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tarfile.open(archive_path, \"r:gz\").extractall(path=target_dir)\n"
     ]
    }
   ],
   "source": [
    "# Load sample dataset\n",
    "newsgroups_data = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "documents = newsgroups_data.data[:500]  # Limit to 500 documents for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e602ef1-487f-4f0c-92d4-7ecbdf84eb60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(documents, columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a3154-9404-4604-85cd-9c4171f73a98",
   "metadata": {},
   "source": [
    "## Comparing Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0b105-b5b5-4de9-a80c-5b97bb0593d5",
   "metadata": {},
   "source": [
    "### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acf9a43-ffa2-44f3-8a3e-de895f37b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER Sentiment Analyzer\n",
    "vader_analyzer = SentimentIntensityAnalyzer()\n",
    "df[\"vaderSent\"] = df.text.apply(lambda x: vader_analyzer.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7be11c-b07d-4769-a94d-18d1d7990bb6",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae8f718-b5a8-47e0-8bd4-c160fbc14f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"trunc_text\"] = df.text.apply(lambda x: x[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a98838-cdd9-418a-841f-8ee5866f5a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1548e393301842b48a37801578c547be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf33969158d4b3ea9313f691d8987fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fd1f7497ec4566918853488dc16f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a019fdde714968b144954f6ec72769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bert_classifier \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bert_scores \u001b[38;5;241m=\u001b[39m bert_classifier(df\u001b[38;5;241m.\u001b[39mtrunc_text\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:168\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[0;32m--> 168\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1448\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1445\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1446\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1447\u001b[0m     )\n\u001b[0;32m-> 1448\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(final_iterator)\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:126\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    127\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:127\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    126\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 127\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1375\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1374\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m-> 1375\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFramework \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1272\u001b[0m, in \u001b[0;36mPipeline._ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_tensor_on_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, device):\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, ModelOutput):\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ModelOutput(\n\u001b[0;32m-> 1272\u001b[0m             {name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1273\u001b[0m         )\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(tensor, device) \u001b[38;5;28;01mfor\u001b[39;00m name, tensor \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:1283\u001b[0m, in \u001b[0;36mPipeline._ensure_tensor_on_device\u001b[0;34m(self, inputs, device)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(item, device) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bert_classifier = pipeline('sentiment-analysis')\n",
    "bert_scores = bert_classifier(df.trunc_text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee01105a-cec8-4469-a7af-3de2f6017509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bertSent\"] =  bert_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792b189-f49e-4549-8636-c66e8b85e46c",
   "metadata": {},
   "source": [
    "### Check the correlation between the two of these sentiment analyses pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705ce75-d301-49b1-af67-59d6b8c8ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc20ba6-850c-40db-b349-771d17d685b4",
   "metadata": {},
   "source": [
    "Find an examples where the two sentiment classifications are opposing. Why might this be the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca180e3-db92-4e18-9a93-95a874ff6ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3076bd61-d425-4197-af63-2caf1790d3de",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc56fd2-ab87-49d6-8e40-944d91e19556",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6a6e3d-6f44-44de-8820-5f113c739f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88d6fec2-80f8-4a93-8348-b8cde7591d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = stopwords.words(\"english\")\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def process_step(one_str):   \n",
    "    nostop_listing = [word for word in wordpunct_tokenize(one_str)\n",
    "                      if word not in list_stopwords]\n",
    "    clean_listing = [porter.stem(word) for word in nostop_listing\n",
    "                    if word.isalpha() \n",
    "                    and len(word) > 3]\n",
    "    clean_listing_str = \" \".join(clean_listing)\n",
    "    return(clean_listing_str)\n",
    "    \n",
    "df[\"text_proc\"] = df.text.apply(process_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df785468-e921-47b2-8d78-3af04e257c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "documents_clean = [gensim.utils.simple_preprocess(doc) for doc in df.text_proc]\n",
    "dictionary = corpora.Dictionary(documents_clean)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778947c4-8e50-4f13-9bc6-230e3492fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f8868cc-eab2-4426-9ec1-75c4e10a4d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.009*\"would\" + 0.004*\"year\" + 0.004*\"also\" + 0.004*\"know\" + 0.003*\"think\" + 0.003*\"includ\" + 0.003*\"they\" + 0.003*\"right\" + 0.003*\"time\" + 0.003*\"mean\"')\n",
      "(1, '0.007*\"would\" + 0.005*\"peopl\" + 0.004*\"use\" + 0.004*\"well\" + 0.004*\"argument\" + 0.004*\"like\" + 0.004*\"thi\" + 0.004*\"know\" + 0.003*\"scsi\" + 0.003*\"look\"')\n",
      "(2, '0.006*\"would\" + 0.005*\"like\" + 0.005*\"peopl\" + 0.004*\"armenian\" + 0.004*\"time\" + 0.003*\"system\" + 0.003*\"think\" + 0.003*\"use\" + 0.003*\"know\" + 0.003*\"make\"')\n",
      "(3, '0.005*\"use\" + 0.004*\"know\" + 0.004*\"would\" + 0.003*\"thi\" + 0.003*\"find\" + 0.003*\"come\" + 0.003*\"time\" + 0.003*\"father\" + 0.003*\"want\" + 0.003*\"window\"')\n",
      "(4, '0.004*\"year\" + 0.004*\"know\" + 0.004*\"want\" + 0.004*\"would\" + 0.004*\"use\" + 0.003*\"time\" + 0.003*\"like\" + 0.003*\"thing\" + 0.003*\"window\" + 0.003*\"even\"')\n",
      "(5, '0.006*\"would\" + 0.005*\"think\" + 0.004*\"know\" + 0.004*\"peopl\" + 0.004*\"like\" + 0.004*\"much\" + 0.004*\"thing\" + 0.004*\"thi\" + 0.003*\"true\" + 0.003*\"armenian\"')\n",
      "(6, '0.006*\"use\" + 0.005*\"anyon\" + 0.004*\"problem\" + 0.004*\"like\" + 0.004*\"would\" + 0.003*\"make\" + 0.003*\"point\" + 0.003*\"could\" + 0.003*\"also\" + 0.003*\"argument\"')\n",
      "(7, '0.005*\"know\" + 0.005*\"use\" + 0.004*\"would\" + 0.004*\"well\" + 0.004*\"need\" + 0.004*\"like\" + 0.003*\"peopl\" + 0.003*\"memori\" + 0.003*\"want\" + 0.003*\"call\"')\n",
      "(8, '0.007*\"would\" + 0.005*\"peopl\" + 0.005*\"like\" + 0.004*\"think\" + 0.004*\"year\" + 0.004*\"want\" + 0.003*\"use\" + 0.003*\"could\" + 0.003*\"control\" + 0.003*\"thi\"')\n",
      "(9, '0.006*\"thi\" + 0.004*\"none\" + 0.003*\"would\" + 0.003*\"like\" + 0.003*\"argument\" + 0.003*\"good\" + 0.003*\"make\" + 0.003*\"look\" + 0.003*\"church\" + 0.003*\"peopl\"')\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words = 10)\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c38cafc-522c-44c8-bcfe-319de0aefbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=94291) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### visualize\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lda_display \u001b[38;5;241m=\u001b[39m gensimvis\u001b[38;5;241m.\u001b[39mprepare(lda_model, corpus, dictionary)\n\u001b[1;32m      3\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39mdisplay(lda_display)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyLDAvis/gensim_models.py:123\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms the Gensim TopicModel and related corpus and dictionary into\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03mthe data structures needed for the visualization.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mSee `pyLDAvis.prepare` for **kwargs.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m opts \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mmerge(_extract_data(topic_model, corpus, dictionary, doc_topic_dist), kwargs)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyLDAvis\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyLDAvis/_prepare.py:432\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# Quick fix for red bar width bug.  We calculate the\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# term frequencies internally, using the topic term distributions and the\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# topic frequencies, rather than using the user-supplied term frequencies.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# For a detailed discussion, see: https://github.com/cpsievert/LDAvis/pull/41\u001b[39;00m\n\u001b[1;32m    430\u001b[0m term_frequency \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(term_topic_freq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 432\u001b[0m topic_info \u001b[38;5;241m=\u001b[39m _topic_info(topic_term_dists, topic_proportion,\n\u001b[1;32m    433\u001b[0m                          term_frequency, term_topic_freq, vocab, lambda_step, R,\n\u001b[1;32m    434\u001b[0m                          n_jobs, start_index)\n\u001b[1;32m    435\u001b[0m token_table \u001b[38;5;241m=\u001b[39m _token_table(topic_info, term_topic_freq, vocab, term_frequency, start_index)\n\u001b[1;32m    436\u001b[0m topic_coordinates \u001b[38;5;241m=\u001b[39m _topic_coordinates(mds, topic_term_dists, topic_proportion, start_index)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyLDAvis/_prepare.py:273\u001b[0m, in \u001b[0;36m_topic_info\u001b[0;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[1;32m    262\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTerm\u001b[39m\u001b[38;5;124m'\u001b[39m: vocab[term_ix],\n\u001b[1;32m    263\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m'\u001b[39m: term_topic_freq\u001b[38;5;241m.\u001b[39mloc[original_topic_id, term_ix],\n\u001b[1;32m    264\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal\u001b[39m\u001b[38;5;124m'\u001b[39m: term_frequency[term_ix],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglift\u001b[39m\u001b[38;5;124m'\u001b[39m: log_lift\u001b[38;5;241m.\u001b[39mloc[original_topic_id, term_ix]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m    268\u001b[0m                        })\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFreq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprob\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloglift\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m     ])\n\u001b[0;32m--> 273\u001b[0m top_terms \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)\n\u001b[1;32m    274\u001b[0m                       (delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls)\n\u001b[1;32m    275\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m ls \u001b[38;5;129;01min\u001b[39;00m _job_chunks(lambda_seq, n_jobs)))\n\u001b[1;32m    276\u001b[0m topic_dfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(topic_top_term_df, \u001b[38;5;28menumerate\u001b[39m(top_terms\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39miterrows(), start_index))\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat([default_term_info] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(topic_dfs))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### visualize\n",
    "lda_display = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b86f9c-d997-4daf-88f1-cab8e9ce603b",
   "metadata": {},
   "source": [
    "## BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0f1a1ed-8cf5-40e2-ab29-9797d9cf76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = newsgroups_data.data[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb8b852f-266a-455b-9883-666abbf70b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c729d9d4414d6fa3635b2633a09e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7226ea91c0814c56a3c41fbfead59f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8bb2baf27b43f8bfc9748a39821726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057f61783ffb4859a41ade4a0e6db6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae07783490ee401d885ae7d8890da8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4861988f88451bb7ffadc0163e3b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e54dfc9d2d41b9b3e85cb9e5d36303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbb0a9a65654f588fab137a50de0029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fd3f4681cc4b888c710ec9c89381b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059b168208cb4f8683c712945cf2e854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828b2810821e4373948ea76b0222230b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 7.6 s, total: 49.1 s\n",
      "Wall time: 6min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "531951d0-1c01-40a2-b001-9e06867a6c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>645</td>\n",
       "      <td>-1_the_to_of_and</td>\n",
       "      <td>[the, to, of, and, is, for, it, in, that, you]</td>\n",
       "      <td>[Hi Netters,\\n\\nAs promised, here are the summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>0_he_the_in_team</td>\n",
       "      <td>[he, the, in, team, to, and, game, was, play, ...</td>\n",
       "      <td>[1992-93 Los Angeles Kings notes.\\n-----------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1_is_of_the_that</td>\n",
       "      <td>[is, of, the, that, to, not, and, jesus, it, in]</td>\n",
       "      <td>[To what follows, our moderator has already an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>2_dos_for_good_excellent</td>\n",
       "      <td>[dos, for, good, excellent, offer, 150, shippi...</td>\n",
       "      <td>[\\n\\n    What phony names? My name is clearly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>3_of_it_the_is</td>\n",
       "      <td>[of, it, the, is, to, in, that, and, are, you]</td>\n",
       "      <td>[\\nAll true.  And all good points.\\n\\n\\n\\nWell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>4_israel_the_of_to</td>\n",
       "      <td>[israel, the, of, to, and, in, that, you, is, by]</td>\n",
       "      <td>[\\n   CHECK MENAHEM BEGIN DAIRIES (published b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>5_deletion_huh_david_</td>\n",
       "      <td>[deletion, huh, david, , , , , , , ]</td>\n",
       "      <td>[David\\n\\n\\n, \\nHuh?,  \\n(Deletion)\\n ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>6_space_the_and_nasa</td>\n",
       "      <td>[space, the, and, nasa, of, for, to, shuttle, ...</td>\n",
       "      <td>[Archive-name: space/new_probes\\nLast-modified...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>7_gun_the_of_to</td>\n",
       "      <td>[gun, the, of, to, that, and, in, is, be, was]</td>\n",
       "      <td>[\\nThe Supreme Court seems to disagree with yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>8_to_the_clipper_encryption</td>\n",
       "      <td>[to, the, clipper, encryption, chip, key, be, ...</td>\n",
       "      <td>[\\n  &gt; Clipper might be a good way to cover th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>9_car_the_and_engine</td>\n",
       "      <td>[car, the, and, engine, to, it, for, you, is, in]</td>\n",
       "      <td>[\\n\\nGood point. I have no idea how either of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>10_my_bike_to_you</td>\n",
       "      <td>[my, bike, to, you, the, in, on, it, is, and]</td>\n",
       "      <td>[\\n\\njust to satiate my curiosity, why would t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>11_card_video_drivers_the</td>\n",
       "      <td>[card, video, drivers, the, monitor, with, hav...</td>\n",
       "      <td>[I have a Radius Precision Color 24x video car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>12_files_tiff_file_format</td>\n",
       "      <td>[files, tiff, file, format, image, scodal, con...</td>\n",
       "      <td>[Howdy all,\\n\\n\\tI was wondering if people cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>13_and_the_they_were</td>\n",
       "      <td>[and, the, they, were, was, armenian, in, of, ...</td>\n",
       "      <td>[Accounts of Anti-Armenian Human Right Violati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>14_memory_dos_windows_machine</td>\n",
       "      <td>[memory, dos, windows, machine, the, with, it,...</td>\n",
       "      <td>[Howdy\\n\\nWe have been having a real problem w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>15_window_widget_the_to</td>\n",
       "      <td>[window, widget, the, to, height, widgets, is,...</td>\n",
       "      <td>[I am writing a custom widget to support the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>16_health_tobacco_smokeless_coli</td>\n",
       "      <td>[health, tobacco, smokeless, coli, o157h7, amo...</td>\n",
       "      <td>[Had a deal with Jay Hayes from Deleware and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>17_available_motif_on_is</td>\n",
       "      <td>[available, motif, on, is, server, version, wi...</td>\n",
       "      <td>[I'd like to compile X11r5 on a Sony NWS-1750 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>18_ma_dj_flea_508</td>\n",
       "      <td>[ma, dj, flea, 508, sept, at, 617, 3776, 253, ...</td>\n",
       "      <td>[DJ&gt; Subject: New aircraft TU-154M for leasing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>19_printer_fonts_truetype_print</td>\n",
       "      <td>[printer, fonts, truetype, print, printers, fo...</td>\n",
       "      <td>[\\n#I use xwd/xpr (from the X11R5 dist.) and v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>20_billion_clinton_the_that</td>\n",
       "      <td>[billion, clinton, the, that, dollars, to, gov...</td>\n",
       "      <td>[\\nEven if what Brad says turns out to be accu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>21_car_ford_dealer_new</td>\n",
       "      <td>[car, ford, dealer, new, cost, the, power, was...</td>\n",
       "      <td>[To: Dodge Dart collectors\\n\\nI have a 1964 Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>22_fire_that_they_the</td>\n",
       "      <td>[fire, that, they, the, to, was, would, tanks,...</td>\n",
       "      <td>[\\n\\n\\n\\nWell put, Jim.  I am as concerned abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>23_otis_image_to_files</td>\n",
       "      <td>[otis, image, to, files, will, and, on, of, yo...</td>\n",
       "      <td>[Toronto Siggraph \\n================\\n\\nWhat: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>24_gay_men_gays_are</td>\n",
       "      <td>[gay, men, gays, are, of, and, to, that, homos...</td>\n",
       "      <td>[\\nSo there are less gays, then the gays claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>25_to_that_ted_you</td>\n",
       "      <td>[to, that, ted, you, is, of, me, not, be, it]</td>\n",
       "      <td>[I apologize if this article is slightly confu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>26_den_radius_plane_double</td>\n",
       "      <td>[den, radius, plane, double, sqrtden, 00, poly...</td>\n",
       "      <td>[\\nHere is one by Andrew \"Graphics Gems\" Glass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>27_speed_accelerator_040_mhz</td>\n",
       "      <td>[speed, accelerator, 040, mhz, processor, mb, ...</td>\n",
       "      <td>[I saw the following computer in a store and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>28_jets_investors_hausmann_maddi</td>\n",
       "      <td>[jets, investors, hausmann, maddi, in, sam, jo...</td>\n",
       "      <td>[Excuse me, but if you really new what the sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>29_scsi_scsi1_scsi2_ide</td>\n",
       "      <td>[scsi, scsi1, scsi2, ide, drive, chip, control...</td>\n",
       "      <td>[                                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>30_simms_meg_memory_ram</td>\n",
       "      <td>[simms, meg, memory, ram, ksec, machine, with,...</td>\n",
       "      <td>[Excuse me if this is a frequent question, I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>31_water_steam_plants_cooling</td>\n",
       "      <td>[water, steam, plants, cooling, heat, nuclear,...</td>\n",
       "      <td>[\\nWater. Nuclear stations don't generate elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>32_com1_port_modem_serial</td>\n",
       "      <td>[com1, port, modem, serial, irq, controller, s...</td>\n",
       "      <td>[\\n   Try putting one of the IRQs for your COM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>33_moral_immoral_is_hudson</td>\n",
       "      <td>[moral, immoral, is, hudson, morality, are, th...</td>\n",
       "      <td>[\\nIf you force me to do something, am I moral...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                              Name  \\\n",
       "0      -1    645                  -1_the_to_of_and   \n",
       "1       0    191                  0_he_the_in_team   \n",
       "2       1    144                  1_is_of_the_that   \n",
       "3       2     99          2_dos_for_good_excellent   \n",
       "4       3     87                    3_of_it_the_is   \n",
       "5       4     64                4_israel_the_of_to   \n",
       "6       5     62             5_deletion_huh_david_   \n",
       "7       6     54              6_space_the_and_nasa   \n",
       "8       7     52                   7_gun_the_of_to   \n",
       "9       8     51       8_to_the_clipper_encryption   \n",
       "10      9     47              9_car_the_and_engine   \n",
       "11     10     43                 10_my_bike_to_you   \n",
       "12     11     42         11_card_video_drivers_the   \n",
       "13     12     32         12_files_tiff_file_format   \n",
       "14     13     32              13_and_the_they_were   \n",
       "15     14     27     14_memory_dos_windows_machine   \n",
       "16     15     27           15_window_widget_the_to   \n",
       "17     16     26  16_health_tobacco_smokeless_coli   \n",
       "18     17     25          17_available_motif_on_is   \n",
       "19     18     23                 18_ma_dj_flea_508   \n",
       "20     19     21   19_printer_fonts_truetype_print   \n",
       "21     20     19       20_billion_clinton_the_that   \n",
       "22     21     19            21_car_ford_dealer_new   \n",
       "23     22     19             22_fire_that_they_the   \n",
       "24     23     16            23_otis_image_to_files   \n",
       "25     24     16               24_gay_men_gays_are   \n",
       "26     25     15                25_to_that_ted_you   \n",
       "27     26     14        26_den_radius_plane_double   \n",
       "28     27     14      27_speed_accelerator_040_mhz   \n",
       "29     28     14  28_jets_investors_hausmann_maddi   \n",
       "30     29     13           29_scsi_scsi1_scsi2_ide   \n",
       "31     30     12           30_simms_meg_memory_ram   \n",
       "32     31     12     31_water_steam_plants_cooling   \n",
       "33     32     12         32_com1_port_modem_serial   \n",
       "34     33     11        33_moral_immoral_is_hudson   \n",
       "\n",
       "                                       Representation  \\\n",
       "0      [the, to, of, and, is, for, it, in, that, you]   \n",
       "1   [he, the, in, team, to, and, game, was, play, ...   \n",
       "2    [is, of, the, that, to, not, and, jesus, it, in]   \n",
       "3   [dos, for, good, excellent, offer, 150, shippi...   \n",
       "4      [of, it, the, is, to, in, that, and, are, you]   \n",
       "5   [israel, the, of, to, and, in, that, you, is, by]   \n",
       "6                [deletion, huh, david, , , , , , , ]   \n",
       "7   [space, the, and, nasa, of, for, to, shuttle, ...   \n",
       "8      [gun, the, of, to, that, and, in, is, be, was]   \n",
       "9   [to, the, clipper, encryption, chip, key, be, ...   \n",
       "10  [car, the, and, engine, to, it, for, you, is, in]   \n",
       "11      [my, bike, to, you, the, in, on, it, is, and]   \n",
       "12  [card, video, drivers, the, monitor, with, hav...   \n",
       "13  [files, tiff, file, format, image, scodal, con...   \n",
       "14  [and, the, they, were, was, armenian, in, of, ...   \n",
       "15  [memory, dos, windows, machine, the, with, it,...   \n",
       "16  [window, widget, the, to, height, widgets, is,...   \n",
       "17  [health, tobacco, smokeless, coli, o157h7, amo...   \n",
       "18  [available, motif, on, is, server, version, wi...   \n",
       "19  [ma, dj, flea, 508, sept, at, 617, 3776, 253, ...   \n",
       "20  [printer, fonts, truetype, print, printers, fo...   \n",
       "21  [billion, clinton, the, that, dollars, to, gov...   \n",
       "22  [car, ford, dealer, new, cost, the, power, was...   \n",
       "23  [fire, that, they, the, to, was, would, tanks,...   \n",
       "24  [otis, image, to, files, will, and, on, of, yo...   \n",
       "25  [gay, men, gays, are, of, and, to, that, homos...   \n",
       "26      [to, that, ted, you, is, of, me, not, be, it]   \n",
       "27  [den, radius, plane, double, sqrtden, 00, poly...   \n",
       "28  [speed, accelerator, 040, mhz, processor, mb, ...   \n",
       "29  [jets, investors, hausmann, maddi, in, sam, jo...   \n",
       "30  [scsi, scsi1, scsi2, ide, drive, chip, control...   \n",
       "31  [simms, meg, memory, ram, ksec, machine, with,...   \n",
       "32  [water, steam, plants, cooling, heat, nuclear,...   \n",
       "33  [com1, port, modem, serial, irq, controller, s...   \n",
       "34  [moral, immoral, is, hudson, morality, are, th...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [Hi Netters,\\n\\nAs promised, here are the summ...  \n",
       "1   [1992-93 Los Angeles Kings notes.\\n-----------...  \n",
       "2   [To what follows, our moderator has already an...  \n",
       "3   [\\n\\n    What phony names? My name is clearly ...  \n",
       "4   [\\nAll true.  And all good points.\\n\\n\\n\\nWell...  \n",
       "5   [\\n   CHECK MENAHEM BEGIN DAIRIES (published b...  \n",
       "6             [David\\n\\n\\n, \\nHuh?,  \\n(Deletion)\\n ]  \n",
       "7   [Archive-name: space/new_probes\\nLast-modified...  \n",
       "8   [\\nThe Supreme Court seems to disagree with yo...  \n",
       "9   [\\n  > Clipper might be a good way to cover th...  \n",
       "10  [\\n\\nGood point. I have no idea how either of ...  \n",
       "11  [\\n\\njust to satiate my curiosity, why would t...  \n",
       "12  [I have a Radius Precision Color 24x video car...  \n",
       "13  [Howdy all,\\n\\n\\tI was wondering if people cou...  \n",
       "14  [Accounts of Anti-Armenian Human Right Violati...  \n",
       "15  [Howdy\\n\\nWe have been having a real problem w...  \n",
       "16  [I am writing a custom widget to support the d...  \n",
       "17  [Had a deal with Jay Hayes from Deleware and w...  \n",
       "18  [I'd like to compile X11r5 on a Sony NWS-1750 ...  \n",
       "19  [DJ> Subject: New aircraft TU-154M for leasing...  \n",
       "20  [\\n#I use xwd/xpr (from the X11R5 dist.) and v...  \n",
       "21  [\\nEven if what Brad says turns out to be accu...  \n",
       "22  [To: Dodge Dart collectors\\n\\nI have a 1964 Do...  \n",
       "23  [\\n\\n\\n\\nWell put, Jim.  I am as concerned abo...  \n",
       "24  [Toronto Siggraph \\n================\\n\\nWhat: ...  \n",
       "25  [\\nSo there are less gays, then the gays claim...  \n",
       "26  [I apologize if this article is slightly confu...  \n",
       "27  [\\nHere is one by Andrew \"Graphics Gems\" Glass...  \n",
       "28  [I saw the following computer in a store and w...  \n",
       "29  [Excuse me, but if you really new what the sho...  \n",
       "30  [                                             ...  \n",
       "31  [Excuse me if this is a frequent question, I c...  \n",
       "32  [\\nWater. Nuclear stations don't generate elec...  \n",
       "33  [\\n   Try putting one of the IRQs for your COM...  \n",
       "34  [\\nIf you force me to do something, am I moral...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ba501-bd9a-4306-a36c-3bce35c3bcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe43aaa-f989-4cbb-8db5-4d989c0778ef",
   "metadata": {},
   "source": [
    "## Your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671f6b3-df63-4e54-a52b-1e09f33a68d2",
   "metadata": {},
   "source": [
    "#### Try running BERTopic on the prcessed data (rather than the uncleaned one)\n",
    "#### What do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47c22cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/executing/executing.py:713: DeprecationWarning: ast.Str is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  right=ast.Str(s=sentinel),\n",
      "/opt/anaconda3/lib/python3.12/ast.py:587: DeprecationWarning: Attribute s is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return Constant(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m BERTopic()\n\u001b[0;32m----> 2\u001b[0m topics, probs \u001b[38;5;241m=\u001b[39m topic_model\u001b[38;5;241m.\u001b[39mfit_transform(documents_clean\u001b[38;5;241m.\u001b[39mastype(String))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(documents_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ace2bf-e9cb-4391-b6bf-269f0b8984d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de1551-16c8-40bc-9df7-eb5e09ed175c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd078ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab7102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe81ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e64f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
